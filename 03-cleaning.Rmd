# Data transformation

Describe the process of getting the data into a form in which you could work with it in R. If your code does not lend itself to being including in the .Rmd file, provide a link to the folder or file(s) that contain(s) that code.
Write a draft of the [Data Transformation chapter](https://edav.info/project#report-format)
```{r}
library(tidyverse)
library(ggplot2)
library(readxl)
library(stringr)
library(tidyr)
library(dplyr)
```



## Country Policy Orders
This dataset comes in a csv format, which can be read in using "read.csv()". As described earlier, each row in this dataset is either a start or end of a policy. There is also information on both county and states. For our analysis, we will look at county and states separately. In addition, when we aggregate the number of states that enacted certain policies, we will only look at values where "start_stop" is "start" so we do not count double.

County Policies:
```{r}
county <- read.csv("./data/state_policy_updates_20201202_0721.csv")
county_policy <- county[county$policy_level=='county' & county$start_stop=='start',]
head(county_policy)
```

State:
```{r}
state_policy <- county[county$policy_level == "state" & county$start_stop=='start',]
head(state_policy)
```

Finally, we created this table by counting all the times each state appears in the previous dataframe to see how many policies each state enacted. This information is fed into our map visualization.
```{r}
policy_count <- count(state, state_id)
policy_count$state_abbr <- policy_count$state_id
policy_count
```

## Hospitalization Data
This dataset comes in a csv format, which can be read in using "read.csv()". As seen in the dataset description, there are many different columns with a variety of different values. We are only concentrating on a few of these values in our analysis so we split the dataframe up. We will analyze inpatient bed use which is column index 40 to 51.
```{r}
hospital <- read.csv("./data/reported_hospital_utilization_20201130_2136.csv")
inpatient_bed <- c(1, 40:51)
inpatient_bed_df <- hospital[,inpatient_bed]
inpatient_bed_df
```
We then calculate the proportion of beds used by covid patients, non-covid patients, and empty beds. To do this, we extract total bed "inpatient bed", covid bed "inpatient_beds_used_covid", non-covid bed "inpatient_beds_used - covid_bed", and empty bed "total bed - inpatient_beds_used". 

We also analyze staffing shortages in a similar fashion. Staff information is columns 1-7.
```{r}
staff_shortage <- c(1:7)
staff_shortage_df <- hospital[,staff_shortage]
head(staff_shortage_df)
```

We then calculate the proportion by diving those that reported "critical staffing shortage today yes" over the sum of both yes and no.


## Airlines Covid Data
This dataset comes in a xlsx format, therefore we installed the “readxl” package, and read in the data using the commands from that package. Since there are some extra spaces in the excel sheet, we remade the table into a form that had no blank spaces, and thus easily callable by column name, which is a dataframe in R. Combining all the columns together into a dataframe, we then renamed the columns such that it would be representative of the information in the column. Lastly, since all the data was in character format, we converted all the columns that had numeric data to a numeric form, such that it can be easily used to create graphs and other visual structures to aid us in our exploratory analysis. Our final product of the downloaded data was a dataframe in R, which had columns that were clearly represented by their names, no missing slots or data, and all the data was the right type of class to work with. The top 5 rows of how the dataframe is structured can be seen below. This will be used for different types of analyses on the impact of covid on the airline/travel industry. 

```{r}
data <- read_excel("./data/scheduled-canceled-operated-flights-jan2019-jul2020.xlsx")

year <- c(2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019,
          2019, 2019, 2020, 2020, 2020, 2020, 2020, 2020, 2020)
my_data <- data.frame(year)

for (val in 2:length(data)){
  array <- data[val][[1]]
  array <- array[5:23]
  my_data <- cbind(my_data, array)
}

#rename the columns 
names <- c("year", "month", "Tot_Flights", "Alaska",
           "Allegiant", "American", "Delta", "Frontier", "Hawaiian", 
           "JetBlue", "Southwest", "Spirit", "United")
names(my_data) <- names 

#convert to numeric 
my_data$Tot_Flights <- as.numeric(my_data$Tot_Flights)
my_data$Alaska <- as.numeric(my_data$Alaska)
my_data$Allegiant <- as.numeric(my_data$Allegiant)
my_data$American <- as.numeric(my_data$American)
my_data$Delta <- as.numeric(my_data$Delta)
my_data$Frontier <- as.numeric(my_data$Frontier)
my_data$Hawaiian <- as.numeric(my_data$Hawaiian)
my_data$JetBlue <- as.numeric(my_data$JetBlue)
my_data$Southwest <- as.numeric(my_data$Southwest)
my_data$Spirit <- as.numeric(my_data$Spirit)
my_data$United <- as.numeric(my_data$United)

head(my_data)
```

## Restaurant data
Two datasets come in a csv format, which can be read in using R commands. Each row contains information of a country or a state and each columns represent different dates. To clean this data we want to change the date columns to one column.
```{r}
restaurant = read.csv("./data/YoY_Seated_Diner_Data-2.csv")
restaurant1 = restaurant %>% pivot_longer(cols = starts_with("X"),
                           names_to = "Date",
                           values_to = "Percentage")%>%
               mutate(Date = paste0("2020.",str_remove(Date,"X")))%>%
               mutate(Date = as.Date(chartr(old = ".", new = "-", Date)))
reopen = read.csv("./data/YoY_Reopened_Seated_Diner_Data.csv")
reopen1 = reopen %>% pivot_longer(cols = starts_with("X"),
                           names_to = "Date",
                           values_to = "Percentage")%>%
               mutate(Date = paste0("2020.",str_remove(Date,"X")))%>%
               mutate(Date = as.Date(chartr(old = ".", new = "-", Date)))
```
The original YoY_Seated_Diner_Data-2.csv file contains information about 8 country of 60 state and 60 cities, and the reopen dataset contains 8 countries and 9 states, including 8 US states. Here we only extract US state and nationwide information.

```{r}
us_states = c('Alabama','Arizona','California','Colorado', 'Connecticut',
       'District of Columbia','Florida', 'Georgia', 'Hawaii', 'Illinois',
       'Indiana', 'Kansas', 'Kentucky', 'Louisiana',
       'Maryland', 'Massachusetts', 'Michigan',
       'Minnesota', 'Missouri', 'Nebraska', 'Nevada', 'New Jersey',
       'New Mexico', 'New York', 'North Carolina', 'Ohio', 'Oklahoma', 'Oregon',
       'Pennsylvania','Rhode Island', 'South Carolina', 'Tennessee', 
       'Texas', 'Utah', 'Virginia', 'Washington', 'Wisconsin')

restaurant_state = restaurant1[restaurant1$Type == 'state',]
restaurant_state = restaurant_state[restaurant_state$Name %in% us_states,]
US.nation.res = restaurant1[which(restaurant1$Type=="country" & restaurant1$Name=="United States"), ]

reopen_state = reopen1[reopen1$Type == 'state',]
reopen_state = reopen_state[reopen_state$Name %in% us_states,]
```

## US COVID Cases Data
US-state data is in csv format and we can read it directly into R. It contains cumulative COVID case numbers by states of each day. We want to see the daily new cases by substract the cumulative data by the data of previous day.
```{r}
us_case = read.csv("./data/us-states.csv")
US_case_by_date = US_case %>%
  mutate(date = as.Date(date))%>%
  group_by(date) %>%
  summarize(cumu_sum = sum(cases)) %>%
  mutate(daily_new = cumu_sum-lag(cumu_sum)) %>%
  drop_na()
```

